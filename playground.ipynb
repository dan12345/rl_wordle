{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config = {'use_only_solutions': True, 'word_len': 3, 'num_episodes_to_train': 10000000, 'greedy_player': False, 'reward_success': 15, 'reward_failure': -15, 'reward_yellow': 0.5, 'reward_green': 1.5, 'rounds_to_failure': 6, 'sync_every': 1000, 'learn_every': 3, 'lr': 0.00025, 'gamma': 0.9, 'n_embd': 64, 'n_head': 2, 'n_layer': 3, 'dropout': 0, 'save_every': 100000, 'burnin': 1000, 'exploration_rate_decay': 0.999991, 'exploration_rate_min': 0, 'batch_size': 32, 'memory_size': 1000, 'debug': False, 'log_every': 5000, 'save_dir': PosixPath('checkpoints/2023-03-19T18-13-04')}\n",
      "evaluating greedy agent\n",
      "state is !canWWWforWWWbut reward is 15 solution is but\n",
      "state is !webWGWsex reward is 15 solution is sex\n",
      "state is !hisWWWdayWWYyou reward is 15 solution is you\n",
      "state is !anyWWWwhoWYWhisGWWher reward is 15 solution is her\n",
      "state is !topWWWhadWGYday reward is 15 solution is day\n",
      "played 2000 games, won 100.0% of games, average game length for wins 3.273\n",
      "evaluating expectation agent\n",
      "state is !oneWGWand reward is 15 solution is and\n",
      "state is !one reward is 15 solution is one\n",
      "state is !oneWWYset reward is 15 solution is set\n",
      "state is !oneWWWdayWGWwasWGGhas reward is 15 solution is has\n",
      "state is !oneWWWdayWGGmayWGGway reward is 15 solution is way\n",
      "played 2000 games, won 100.0% of games, average game length for wins 2.891\n",
      "transformer model initialized, number parameters =  156456\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from expectation_player import ExpectationPlayer\n",
    "from greedy_player import GreedyWordlePlayer\n",
    "from wordle_environment import WordleEnvironment\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from rl_player import RLPlayer\n",
    "from game_room import evaluate_player, train_player\n",
    "use_only_solutions = True\n",
    "word_len = 3\n",
    "num_episodes_to_train = 10000000\n",
    "greedy_player = False\n",
    "reward_success = 15\n",
    "reward_failure = -15\n",
    "reward_yellow = 0.5\n",
    "reward_green = 1.5\n",
    "rounds_to_failure = 6\n",
    "sync_every = 1000\n",
    "learn_every = 3\n",
    "lr = 0.00025\n",
    "gamma = 0.9\n",
    "n_embd = 64\n",
    "n_head = 2\n",
    "n_layer = 3\n",
    "dropout = 0\n",
    "save_every = 100000\n",
    "burnin = 1000\n",
    "learn_every = 3\n",
    "exploration_rate_decay = 0.999991\n",
    "exploration_rate_min = 0\n",
    "batch_size = 32\n",
    "memory_size = 1000\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "debug = False\n",
    "log_every = 5000\n",
    "# create config variable from global variables (except for those starting with _)\n",
    "config = {k: v for k, v in globals().items() if not k.startswith('_') and isinstance(v, (int, float, bool, str))}\n",
    "config['save_dir'] = save_dir\n",
    "print(f\"config = {config}\")\n",
    "device = 'cpu'\n",
    "\n",
    "env = WordleEnvironment(config)\n",
    "\n",
    "# get greedy score for comparison\n",
    "greedy_agent = GreedyWordlePlayer(config)\n",
    "print(\"evaluating greedy agent\")\n",
    "__ = evaluate_player(greedy_agent, env, num_games_to_evaluate=2000)\n",
    "\n",
    "expectation_player = ExpectationPlayer(config)\n",
    "print(\"evaluating expectation agent\")\n",
    "__ = evaluate_player(expectation_player, env, num_games_to_evaluate=2000)\n",
    "\n",
    "# now train RL agent\n",
    "agent = GreedyWordlePlayer(config) if config['greedy_player'] else RLPlayer(config, device)\n",
    "train_player(agent, env, config, save_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 2, 10])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "a = nn.Linear(4, 10)\n",
    "b = torch.rand(2, 4)\n",
    "m = torch.randn(10, 10)\n",
    "c = a(b)\n",
    "c = c.unsqueeze(0)\n",
    "(c @ m).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1.],\n        [1., 1.],\n        [1., 1.]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2,3)\n",
    "#transpose\n",
    "a.t()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[b\"config: {'use_only_solutions': True, 'word_len': 3, 'num_episodes_to_train': 10000000, 'greedy_player': False, 'reward_success': 15, 'reward_failure': -15, 'reward_yellow': 0.5, 'reward_green': 1.5, 'rounds_to_failure': 6, 'sync_every': 1000, 'learn_every': 3, 'lr': 0.00025, 'gamma': 0.9, 'n_embd': 128, 'n_head': 4, 'n_layer': 4, 'dropout': 0, 'save_every': 100000, 'burnin': 1000, 'exploration_rate_decay': 0.999995, 'exploration_rate_min': 0.001, 'batch_size': 32, 'memory_size': 1000, 'debug': False, 'log_every': 20000, 'save_dir': PosixPath('checkpoints/2023-03-19T21-38-47')}\\n\",\n b' Episode    StepWinPercent AvgWinLen   Epsilon     MeanReward     MeanLength       MeanLoss     MeanQValue      TimeDelta                Time\\n',\n b'   20000  115339    13.600     2.779     0.562         -8.232          5.628          0.813         -9.798       2788.337 2023-03-19T22:25:16\\n',\n b'   40000  227615    31.000     2.832     0.320         -6.094          5.488          1.113         -9.580       2852.655 2023-03-19T23:12:48\\n',\n b'   60000  333367    31.800     3.000     0.189         -2.733          5.161          1.804         -8.014       2741.202 2023-03-19T23:58:29\\n',\n b'   80000  434474    46.000     2.887     0.114         -0.453          4.941          2.163         -7.191       2652.523 2023-03-20T00:42:42\\n',\n b'  100000  530187    54.400     2.890     0.071          2.637          4.678          2.886         -5.283       2520.660 2023-03-20T01:24:43\\n',\n b'  120000  619885    70.600     3.266     0.045          5.686          4.383          3.206         -3.137       2356.460 2023-03-20T02:03:59\\n',\n b'  140000  704562    78.800     3.310     0.030          9.508          4.137          3.360          0.549       2254.985 2023-03-20T02:41:34\\n',\n b'  160000  783259    89.400     3.414     0.020         12.973          3.843          2.356          6.793       2106.100 2023-03-20T03:16:40\\n',\n b'  180000  858699    91.000     3.308     0.014         15.493          3.683          1.300         10.324       2020.166 2023-03-20T03:50:20\\n',\n b'  200000  930979   100.000     3.516     0.010         17.123          3.526          0.543         12.485       1839.689 2023-03-20T04:21:00\\n',\n b'  220000 1005492    95.600     3.496     0.007         17.722          3.636          0.524         12.971       1917.028 2023-03-20T04:52:57\\n',\n b'  240000 1079317    91.400     3.499     0.005         18.033          3.598          0.469         13.153       1902.406 2023-03-20T05:24:39\\n',\n b'  260000 1153424   100.000     3.390     0.003         17.233          3.621          0.865         11.947       1909.139 2023-03-20T05:56:29\\n',\n b'  280000 1224106   100.000     3.390     0.002         18.146          3.449          0.391         13.501       1800.736 2023-03-20T06:26:29\\n',\n b'  300000 1294602   100.000     3.414     0.002         18.448          3.439          0.329         13.758       1758.404 2023-03-20T06:55:48\\n',\n b'  320000 1364478    98.600     3.286     0.001         18.194          3.411          0.347         13.608       1715.957 2023-03-20T07:24:24\\n',\n b'  340000 1436008    96.000     3.565     0.001         18.062          3.485          0.425         13.427       1826.659 2023-03-20T07:54:50\\n']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"checkpoints/2023-03-19T21-38-47/log\", 'rb') as f:\n",
    "    lines = f.readlines()Ã‡\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
